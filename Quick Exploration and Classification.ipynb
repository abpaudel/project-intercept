{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_type</th>\n",
       "      <th>spam</th>\n",
       "      <th>manual_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camila here are you still looking for hookup ?...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Other Site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Short Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heya, you responded to my CityXGuide ad a whil...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Other Site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you know that law enforcement are using Cit...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Other Site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;img&gt;https://api.twilio.com/2010-04-01/Account...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Image</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  conversation_type  \\\n",
       "0  Camila here are you still looking for hookup ?...                  1   \n",
       "1                                                 hi                  1   \n",
       "2  Heya, you responded to my CityXGuide ad a whil...                  1   \n",
       "3  Do you know that law enforcement are using Cit...                  1   \n",
       "4  <img>https://api.twilio.com/2010-04-01/Account...                  1   \n",
       "\n",
       "    spam    manual_class  \n",
       "0  False      Other Site  \n",
       "1  False  Short Greeting  \n",
       "2  False      Other Site  \n",
       "3  False      Other Site  \n",
       "4  False           Image  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/inbound_messages.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    206\n",
       "True     108\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 314 entries, 0 to 313\n",
      "Data columns (total 4 columns):\n",
      "text                 310 non-null object\n",
      "conversation_type    314 non-null int64\n",
      "spam                 314 non-null bool\n",
      "manual_class         287 non-null object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 7.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['text', 'spam']\n",
    "train = train[columns].dropna()\n",
    "X = train.text\n",
    "y = train.spam\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF with NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('clf',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__alpha': [0.01, 0.1, 0.5, 1],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', MultinomialNB())])\n",
    "\n",
    "tf_params = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'clf__alpha': [0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(nb_tf, param_grid=tf_params, cv = 5, return_train_score=True)\n",
    "model.fit(Xtrain, ytrain)\n",
    "#model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 1, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': 'english'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'clf__alpha': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.882373637163254\n",
      "Test accuracy: 0.6825589886933091\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=0)\n",
    "cv_results = cross_validate(nb_tf, X.ravel(), y, cv=kfold,return_train_score=True)\n",
    "print(\"Train accuracy: {}\".format(cv_results['train_score'].mean()))\n",
    "print(\"Test accuracy: {}\".format(cv_results['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8847926267281107\n",
      "Test accuracy: 0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "tfidf_best = model.best_estimator_\n",
    "print('Train accuracy: {}'.format(model.score(Xtrain, ytrain)))\n",
    "print('Test accuracy: {}'.format(model.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    202\n",
       "True     108\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.spam.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF with NaiveBayes (Upsampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     202\n",
       "False    202\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_0, count_class_1 = train.spam.value_counts()\n",
    "\n",
    "class_0 = train[train.spam == False]\n",
    "class_1 = train[train.spam == True]\n",
    "\n",
    "class_1_plus = class_1.sample(count_class_0, replace=True)\n",
    "train_upsampled = pd.concat([class_0, class_1_plus], axis=0)\n",
    "\n",
    "train_upsampled.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('clf',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__alpha': [0.01, 0.1, 0.5, 1],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_upsampled.text\n",
    "y = train_upsampled.spam\n",
    "Xtrain_, Xtest_, ytrain_, ytest_ = train_test_split(X, y, stratify=y, test_size=0.3, random_state=2)\n",
    "model = GridSearchCV(nb_tf, param_grid=tf_params, cv = 4, return_train_score=True)\n",
    "model.fit(Xtrain_, ytrain_)\n",
    "#model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01,\n",
       " 'tfidf__ngram_range': (1, 3),\n",
       " 'tfidf__stop_words': 'english'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On upsampled test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy_: 0.9858156028368794\n",
      "Test accuracy_: 0.7868852459016393\n"
     ]
    }
   ],
   "source": [
    "tfidf_best = model.best_estimator_\n",
    "print('Train accuracy_: {}'.format(tfidf_best.score(Xtrain_, ytrain_)))\n",
    "print('Test accuracy_: {}'.format(tfidf_best.score(Xtest_, ytest_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.69      0.78        61\n",
      "        True       0.59      0.84      0.69        32\n",
      "\n",
      "    accuracy                           0.74        93\n",
      "   macro avg       0.74      0.77      0.74        93\n",
      "weighted avg       0.79      0.74      0.75        93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, tfidf_best.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On original test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: {}'.format(tfidf_best.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction on TD-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                        TruncatedSVD(algorithm='randomized',\n",
       "                                                     n_components=2, n_iter=5,\n",
       "                                                     random_state=None,\n",
       "                                                     tol=0.0)),\n",
       "                                       ('clf',\n",
       "                                        GaussianNB(priors=None,\n",
       "                                                   var_smoothing=1e-09))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'pca__n_components': [800],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                  ('pca', TruncatedSVD()),\n",
    "                ('clf', GaussianNB())])\n",
    "\n",
    "tf_params = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'pca__n_components': [800],\n",
    "    #'clf__alpha': [0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(nb_tf, param_grid=tf_params, cv = 4, return_train_score=True)\n",
    "model.fit(Xtrain, ytrain)\n",
    "#model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 800,\n",
       " 'tfidf__ngram_range': (1, 3),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.695852534562212\n",
      "Test accuracy: 0.4946236559139785\n"
     ]
    }
   ],
   "source": [
    "tfidf_best = model.best_estimator_\n",
    "print('Train accuracy: {}'.format(model.score(Xtrain, ytrain)))\n",
    "print('Test accuracy: {}'.format(model.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ab/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__C': [0.01, 0.1, 1, 10],\n",
       "                         'clf__kernel': ['linear', 'rbf'],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tfidf__stop_words': [None, 'english']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('clf', SVC())])\n",
    "\n",
    "tf_params = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__stop_words': [None, 'english'],\n",
    "    'clf__kernel': ['linear', 'rbf'],\n",
    "    'clf__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(nb_tf, param_grid=tf_params, cv = 4, return_train_score=True)\n",
    "model.fit(Xtrain, ytrain)\n",
    "#model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1,\n",
       " 'clf__kernel': 'linear',\n",
       " 'tfidf__ngram_range': (1, 3),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9585253456221198\n",
      "Test accuracy: 0.7634408602150538\n"
     ]
    }
   ],
   "source": [
    "tfidf_best = model.best_estimator_\n",
    "print('Train accuracy: {}'.format(model.score(Xtrain, ytrain)))\n",
    "print('Test accuracy: {}'.format(model.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.75      0.81        61\n",
      "        True       0.62      0.78      0.69        32\n",
      "\n",
      "    accuracy                           0.76        93\n",
      "   macro avg       0.75      0.77      0.75        93\n",
      "weighted avg       0.78      0.76      0.77        93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest, model.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.5, 'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.908446438156583\n",
      "Test accuracy: 0.7137195121951219\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
